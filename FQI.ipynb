{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from env import MultiAgentEnv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "from new_env import New_env\n",
    "import gymnasium as gym\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train length 64\n",
    "\n",
    "X_train = pd.read_csv('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/X_train.csv')\n",
    "X_train['employee embedding'] = X_train['employee embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float64))\n",
    "X_train['company embedding'] = X_train['company embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y TRAIN\n",
    "y_train = pd.read_csv('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/y_train.csv', index_col=0)\n",
    "encoding_map = {\n",
    "        \"Assistant\": 0,\n",
    "        \"Executive\": 1,\n",
    "        \"Manager\": 2,\n",
    "        \"Director\": 3,\n",
    "        \n",
    "    }\n",
    "\n",
    "y_train = np.array([encoding_map[category] for category in y_train['position']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "1    17793\n",
       "0     9023\n",
       "3     1356\n",
       "2     1101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length 64 !!\n",
    "\n",
    "# Convert embeddings columns in PyTorch tensors \n",
    "employee_embedding_tensor = torch.tensor(np.vstack(X_train['employee embedding'].values), dtype=torch.float64)\n",
    "company_embedding_tensor = torch.tensor(np.vstack(X_train['company embedding'].values), dtype=torch.float64)\n",
    "\n",
    "# Concatenate both\n",
    "combined_tensor = torch.cat([employee_embedding_tensor, company_embedding_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29273, 6)\n",
      "combined tensor shape torch.Size([29273, 38])\n"
     ]
    }
   ],
   "source": [
    "# Length 38 !!\n",
    "#Reduce company embeddings to length 6 \n",
    "\n",
    "embeddings_company = np.vstack(X_train['company embedding'].values)\n",
    "\n",
    "\n",
    "# Création de l'objet PCA pour réduire à 6 dimensions\n",
    "pca = PCA(n_components=6)\n",
    "\n",
    "# Fit et transformation des embeddings\n",
    "reduced_embeddings = pca.fit_transform(embeddings_company)\n",
    "\n",
    "print(reduced_embeddings.shape) \n",
    "# Convert embeddings columns in PyTorch tensors \n",
    "employee_embedding_tensor = torch.tensor(np.vstack(X_train['employee embedding'].values), dtype=torch.float64)\n",
    "company_embedding_tensor = torch.tensor(reduced_embeddings, dtype=torch.float64)\n",
    "\n",
    "# Concatenate both\n",
    "combined_tensor = torch.cat([employee_embedding_tensor, company_embedding_tensor], dim=1)\n",
    "print(\"combined tensor shape\", combined_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "X_test = pd.read_csv('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/X_train.csv')\n",
    "X_test['employee embedding'] = X_test['employee embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float64))\n",
    "X_test['company embedding'] = X_test['company embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST length 64\n",
    "\n",
    "# Convertir les colonnes d'embeddings en tensors PyTorch\n",
    "employee_embedding_tensor_test = torch.tensor(np.vstack(X_test['employee embedding'].values), dtype=torch.float64)\n",
    "company_embedding_tensor_test = torch.tensor(np.vstack(X_test['company embedding'].values), dtype=torch.float64)\n",
    "\n",
    "# Concaténer les deux tensors le long de la dimension appropriée (axis=1 pour ajouter des colonnes)\n",
    "combined_tensor_test = torch.cat([employee_embedding_tensor_test, company_embedding_tensor_test], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29273, 6)\n",
      "combined tensor shape torch.Size([29273, 38])\n"
     ]
    }
   ],
   "source": [
    "# TEST length 38 \n",
    "\n",
    "embeddings_company_test = np.vstack(X_test['company embedding'].values)\n",
    "\n",
    "\n",
    "# Fit et transformation des embeddings\n",
    "reduced_embeddings_test = pca.transform(embeddings_company_test)\n",
    "\n",
    "print(reduced_embeddings.shape) \n",
    "# Convert embeddings columns in PyTorch tensors \n",
    "employee_embedding_tensor_test = torch.tensor(np.vstack(X_test['employee embedding'].values), dtype=torch.float64)\n",
    "company_embedding_tensor_test = torch.tensor(reduced_embeddings_test, dtype=torch.float64)\n",
    "\n",
    "# Concatenate both\n",
    "combined_tensor_test = torch.cat([employee_embedding_tensor_test, company_embedding_tensor_test], dim=1)\n",
    "print(\"combined tensor shape\", combined_tensor_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y TEST\n",
    "y_test = pd.read_csv(\"/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/y_test.csv\", index_col=1)\n",
    "encoding_map = {\n",
    "        \"Assistant\": 0,\n",
    "        \"Executive\": 1,\n",
    "        \"Manager\": 2,\n",
    "        \"Director\": 3,\n",
    "    }\n",
    "y_test = np.array([encoding_map[category] for category in y_test['position']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(combined_tensor, y_train)\n",
    "X_oversampled, y_oversampled = shuffle(X_oversampled, y_oversampled, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnderSampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from imblearn.under_sampling import NearMiss\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "X_undersampled, y_undersampled = undersample.fit_resample(np.array(combined_tensor), y_train)\n",
    "X_undersampled, y_undersampled = shuffle(X_undersampled, y_undersampled, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4404, 38)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_undersampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, ..., 2, 3, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_undersampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify embeddings with constrastive learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive learning model \n",
    "\n",
    "class EmbeddingAdjustmentModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(EmbeddingAdjustmentModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tensor_undersampled = torch.tensor(X_undersampled)\n",
    "embedding_dim = combined_tensor.shape[1]\n",
    "output_dim = 32\n",
    "model = EmbeddingAdjustmentModel(embedding_dim, output_dim)\n",
    "model.load_state_dict(torch.load('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/model_contrast_32.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_embeddings_train = model(combined_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4404, 32])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(env,  disable_tqdm=False, print_done_states=False):\n",
    "    s, _ = env.reset(True)\n",
    "    S = []\n",
    "    A = []\n",
    "    rewards = []\n",
    "    S2 = []\n",
    "    SA = []\n",
    "    done= False\n",
    "    D = []\n",
    "    #print(\"s\", s)\n",
    "    #print(\"true position\", env.y[env.index])\n",
    "\n",
    "    for _ in tqdm(range(env.Emb.shape[0]-1), disable=disable_tqdm):\n",
    "        #print(\"index\", env.index)\n",
    "        #print(len(S))\n",
    "        while done==False:\n",
    "            a = env.sample_action()\n",
    "            s2, emb2s2, r, done, _ = env.step(a)\n",
    "            #print(\"next state preidcted\", s2)\n",
    "            #print(\"next embedding state \", emb2s2)\n",
    "            S.append(s)\n",
    "            #print('shape S', len(S))\n",
    "            A.append(a)\n",
    "            sa = torch.cat([s, torch.tensor(a)])\n",
    "            SA.append(sa)\n",
    "            rewards.append(r)\n",
    "            #print(\"reward\", r)\n",
    "            S2.append(emb2s2)\n",
    "            D.append(done)\n",
    "            #if done:\n",
    "                #s, _ = env.reset(False)\n",
    "                #print(\"new embedding\", s)\n",
    "                #print(\"true position\", env.y[env.index])\n",
    "                #print(\"done!\")\n",
    "            #else:\n",
    "            s = emb2s2\n",
    "        s, _ = env.reset(False)\n",
    "        done = False\n",
    "    S2 = np.array(S2)\n",
    "    S = np.array(S)\n",
    "    A = np.array(A)\n",
    "    D = np.array(D)\n",
    "    SA = np.array(SA)\n",
    "    rewards = np.array(rewards)\n",
    "    return S, A, rewards, S2, D, SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/p_k7b1g12kz9ykb1cx0n70w00000gn/T/ipykernel_54388/2316599510.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sa = torch.cat([s, torch.tensor(a)])\n",
      "100%|██████████| 29272/29272 [00:49<00:00, 592.00it/s] \n"
     ]
    }
   ],
   "source": [
    "env = New_env(combined_tensor, y_train)\n",
    "S, A, R, S2, D, SA = collect_samples(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4404"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.Emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26285,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_fqi(S, A, R, S2, D, SA, iterations, nb_actions=2, gamma=0.9, disable_tqdm=False):\n",
    "    nb_samples = S.shape[0]\n",
    "    Qfunctions = []\n",
    "    #SA = np.append(S,A,axis=1)\n",
    "    for iter in tqdm(range(iterations), disable=disable_tqdm):\n",
    "        #print(\"iteration\", iter)\n",
    "        if iter==0:\n",
    "            value=R.copy()\n",
    "        else:\n",
    "            Q2 = np.zeros((nb_samples,nb_actions))\n",
    "            for a2 in range(nb_actions):\n",
    "                A2 = torch.full((S2.shape[0], 1), a2)\n",
    "                #print(A2.shape)\n",
    "                S2A2 = torch.cat([torch.from_numpy(S2), A2], dim=1)\n",
    "                S2A2_array = np.array(S2A2)\n",
    "                #print(\"shaoe A2S2\", S2A2_array.shape)\n",
    "                predictions = Qfunctions[-1].predict(S2A2_array)\n",
    "                #print(\"shape pred\", predictions.shape)\n",
    "                Q2[:,a2] = Qfunctions[-1].predict(S2A2_array)\n",
    "            max_Q2 = np.max(Q2,axis=1)\n",
    "            #print(\"max Q2\",max_Q2[:10])\n",
    "            print(np.dot((1-D.flatten()),max_Q2))\n",
    "            value = R + gamma*(1-D.flatten())*max_Q2\n",
    "            #print(\"cumulated reward\", value)\n",
    "            #print(\"value\", value.shape)\n",
    "        Q = XGBRegressor()\n",
    "        Q.fit(SA,value)\n",
    "        #print(\"cumulated reward\", value)\n",
    "        Qfunctions.append(Q)\n",
    "    return Qfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:33,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26742.651432616054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:36,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9081.41293703951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:12<00:29,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9569.657403488061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:16<00:23,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26446.673407736234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:20<00:19,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41015.70767913805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:24<00:15,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54144.00813992316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:27<00:11,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65461.29393131286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:31<00:07,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75893.51113826537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:35<00:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87021.18077568233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:39<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "qfunctions = rf_fqi(S, A, R, S2, D, SA, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_action(Q,s,nb_actions=2):\n",
    "    Qsa = []\n",
    "    for a in range(nb_actions):\n",
    "        #print(\"s\", s)\n",
    "        #print(\"a\", torch.tensor([a]))\n",
    "        sa = torch.cat([s, torch.tensor([a])], dim=0)\n",
    "        sa = np.array(sa)\n",
    "        #print(sa.reshape(-1,1).shape)\n",
    "        #print(\"prediction\", Q.predict(sa.reshape(1, -1)))\n",
    "        Qsa.append(Q.predict(sa.reshape(1, -1)))\n",
    "    #print(\"Qsa\", Qsa)\n",
    "    return np.argmax(Qsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action chosen 1\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/29273 [00:00<1:39:17,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 1\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([1.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/29273 [00:00<1:30:15,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s tensor([0.])\n",
      "target 1\n",
      "action chosen 0\n",
      "s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/29273 [00:00<1:01:55,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "target 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 29272/29273 [08:28<00:00, 57.60it/s] \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 29273 is out of bounds for dimension 0 with size 29273",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m pred\u001b[38;5;241m.\u001b[39mappend(s)\n\u001b[1;32m     26\u001b[0m y_pred\u001b[38;5;241m.\u001b[39mappend(predicted_next_position\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 27\u001b[0m s,_\u001b[38;5;241m=\u001b[39m\u001b[43mcareer_env_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/HrFlow_Data_Challenge/new_env.py:48\u001b[0m, in \u001b[0;36mNew_env.reset\u001b[0;34m(self, first_emb)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 29273 is out of bounds for dimension 0 with size 29273"
     ]
    }
   ],
   "source": [
    "career_env_test = New_env(combined_tensor, y_train)\n",
    "pred=[]\n",
    "y_pred = []\n",
    "s,_ =  career_env_test.reset(True)\n",
    "i=0\n",
    "#for t in tqdm(range(len(y_test))):\n",
    "for t in tqdm(range(len(y_train))):\n",
    "    for k in range(10):\n",
    "        a = greedy_action(qfunctions[-1],s)\n",
    "\n",
    "        predicted_next_position, predicted_next_emb_state, reward, d, _ = career_env_test.step(a)\n",
    "\n",
    "        s = predicted_next_emb_state\n",
    "        if t in [0,1,2,3]:\n",
    "            print(\"action chosen\", a)\n",
    "\n",
    "            print(\"s\", predicted_next_position)\n",
    "            print(\"target\", y_train[i])\n",
    "        #if a ==0:\n",
    "         #   break\n",
    "        \n",
    "        if d:\n",
    "            break\n",
    "    i+=1\n",
    "    pred.append(s)\n",
    "    y_pred.append(predicted_next_position.item())\n",
    "    s,_=career_env_test.reset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  \n",
       "0.0    2817\n",
       "3.0     861\n",
       "2.0     435\n",
       "1.0     291\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3992018691841165"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_undersampled, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nb_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, nb_actions)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def rf_fqi(S, A, R, S2, D, SA, iterations, nb_actions=2, gamma=0.9, disable_tqdm=False):\n",
    "    nb_samples = S.shape[0]\n",
    "    Qfunctions = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_size = SA.shape[1]\n",
    "    hidden_size = 128  # Example size\n",
    "    model = DQN(input_size, hidden_size, 1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    #SA = np.append(S,A,axis=1)\n",
    "    for iter in tqdm(range(iterations), disable=disable_tqdm):\n",
    "        #print(\"iteration\", iter)\n",
    "        if iter==0:\n",
    "            value=R.copy()\n",
    "        else:\n",
    "            Q2 = np.zeros((nb_samples,nb_actions))\n",
    "            for a2 in range(nb_actions):\n",
    "                A2 = torch.full((S2.shape[0], 1), a2)\n",
    "                #print(A2.shape)\n",
    "                S2A2 = torch.cat([torch.from_numpy(S2), A2], dim=1)\n",
    "                S2A2_array = np.array(S2A2)\n",
    "                #print(\"shaoe A2S2\", S2A2_array.shape)\n",
    "                predictions = model(S2A2)\n",
    "                #print(\"shape pred\", predictions.shape)\n",
    "                print(Q2.shape)\n",
    "                print(predictions.shape)\n",
    "                Q2[:,a2] = predictions.detach().squeeze()\n",
    "            max_Q2 = np.max(Q2,axis=1)\n",
    "            #print(\"max Q2\",max_Q2[:10])\n",
    "            print(np.dot((1-D.flatten()),max_Q2))\n",
    "            value = R + gamma*(1-D.flatten())*max_Q2\n",
    "            #print(\"cumulated reward\", value)\n",
    "            #print(\"value\", value.shape)\n",
    "        # Prepare SA and value for training\n",
    "        SA_tensor = torch.from_numpy(SA).float().to(device)\n",
    "        value_tensor = torch.from_numpy(value).float().to(device)\n",
    "        print(SA_tensor.shape)\n",
    "        # Train DNN\n",
    "        #print(\"value\",value.shape)\n",
    "        optimizer.zero_grad()\n",
    "        model = model.double()\n",
    "        predictions = model(SA_tensor.double()).squeeze()\n",
    "        print(predictions.shape)\n",
    "        loss = criterion(predictions.double(), value_tensor.double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model, 'model_FQI_deep.pt')\n",
    "        #print(\"cumulated reward\", value)\n",
    "        #Qfunctions.append(Q)\n",
    "    return model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:01,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-719.408304661079\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:01,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-1771.6366432190007\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:01,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-2816.581003465987\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:01<00:01,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-3855.633643325138\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:01<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-4890.331437044628\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-5922.649880416283\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:01<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-6954.092254589528\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:02<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-7986.394903772739\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:02<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "(26285, 2)\n",
      "torch.Size([26285, 1])\n",
      "-9021.09588889922\n",
      "value (26285,)\n",
      "torch.Size([26285, 40])\n",
      "value (26285,)\n",
      "torch.Size([26285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dict = rf_fqi(S, A, R, S2, D, SA, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class '__main__.DQN'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m modele \u001b[38;5;241m=\u001b[39m DQN(input_size, hidden_size, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodele\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/model_FQI_deep.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m modele\u001b[38;5;241m.\u001b[39meval() \n",
      "File \u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:2104\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \n\u001b[1;32m   2071\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2106\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2107\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class '__main__.DQN'>."
     ]
    }
   ],
   "source": [
    "input_size = SA.shape[1]\n",
    "hidden_size = 128  # Example size\n",
    "device=\"cpu\"\n",
    "modele = DQN(input_size, hidden_size, 1).to(device)\n",
    "\n",
    "modele.load_state_dict(torch.load('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/model_FQI_deep.pt'))\n",
    "modele.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action(network, state):\n",
    "    device = \"cuda\" if next(network.parameters()).is_cuda else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        Q = network(torch.Tensor(state).unsqueeze(0).to(device))\n",
    "        #print(\"Q\", Q)\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_env_test = New_env(torch.tensor(X_undersampled, dtype=torch.float64), torch.tensor(y_undersampled, dtype=torch.float64))\n",
    "pred=[]\n",
    "y_pred = []\n",
    "s,_ =  career_env_test.reset(True)\n",
    "i=0\n",
    "#for t in tqdm(range(len(y_test))):\n",
    "for t in tqdm(range(len(y_undersampled))):\n",
    "    for k in range(5):\n",
    "        a = greedy_action(modele,s)\n",
    "\n",
    "        predicted_next_position, predicted_next_emb_state, reward, d, _ = career_env_test.step(a)\n",
    "\n",
    "        s = predicted_next_emb_state\n",
    "        if t in [0,1,2,3]:\n",
    "            print(\"action chosen\", a)\n",
    "\n",
    "            print(\"s\", predicted_next_position)\n",
    "            print(\"target\", y_undersampled[i])\n",
    "        #if a ==0:\n",
    "         #   break\n",
    "        \n",
    "        if d:\n",
    "            break\n",
    "    i+=1\n",
    "    pred.append(s)\n",
    "    y_pred.append(predicted_next_position.item())\n",
    "    s,_=career_env_test.reset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_action(Q,s,nb_actions=2):\n",
    "    Qsa = []\n",
    "    for a in range(nb_actions):\n",
    "        #print(\"s\", s)\n",
    "        #print(\"a\", torch.tensor([a]))\n",
    "        sa = torch.cat([s, torch.tensor([a])], dim=0)\n",
    "        sa = np.array(sa)\n",
    "        #print(sa.reshape(-1,1).shape)\n",
    "        #print(\"prediction\", Q.predict(sa.reshape(1, -1)))\n",
    "        Qsa.append(Q.predict(sa.reshape(1, -1)))\n",
    "    #print(\"Qsa\", Qsa)\n",
    "    return np.argmax(Qsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0133, -0.3762, -0.6138,  ..., -0.4219, -0.3206, -0.4043],\n",
       "        [-0.2827, -0.0129,  0.2054,  ..., -0.1548,  0.0759, -0.6390],\n",
       "        [ 0.4000, -0.2985, -0.2110,  ..., -0.5598,  0.1031, -0.1492],\n",
       "        ...,\n",
       "        [-0.2505, -0.2068,  0.5609,  ..., -0.1784, -0.3287, -0.4991],\n",
       "        [-0.2505, -0.2068,  0.5609,  ..., -0.8119,  0.0043,  0.2834],\n",
       "        [-0.6191, -0.0630, -0.2045,  ..., -0.3501, -0.6396, -0.5535]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 4403/4404 [05:54<00:00, 12.41it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4404 is out of bounds for dimension 0 with size 4404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print(len(pred))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m y_pred\u001b[38;5;241m.\u001b[39mappend(predicted_next_position\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 25\u001b[0m s,_\u001b[38;5;241m=\u001b[39m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/HrFlow_Data_Challenge/new_env.py:48\u001b[0m, in \u001b[0;36mNew_env.reset\u001b[0;34m(self, first_emb)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual_emb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4404 is out of bounds for dimension 0 with size 4404"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "y_pred = []\n",
    "s,_ =  env.reset(True)\n",
    "\n",
    "for t in tqdm(range(4404)):\n",
    "    stay_a = 0\n",
    "    dbis=False\n",
    "    for k in range(6):\n",
    "    \n",
    "        \n",
    "        a = greedy_action(qfunctions[-1],s)\n",
    "        if a ==0:\n",
    "            stay_a+=1\n",
    "            if stay_a==2:\n",
    "                dbis=True\n",
    "        predicted_next_position, predicted_next_emb_state, reward, d, _ = env.step(a)\n",
    "        #print(\"s\", s)\n",
    "        s = predicted_next_emb_state\n",
    "\n",
    "        if d or dbis:\n",
    "            break\n",
    "    pred.append(s)\n",
    "    #print(len(pred))\n",
    "    y_pred.append(predicted_next_position.item())\n",
    "    s,_=env.reset(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4404\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0    1101\n",
      "1    1101\n",
      "2    1101\n",
      "3    1101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_undersampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "0.0    2299\n",
      "1.0    1089\n",
      "2.0     679\n",
      "3.0     337\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "0.0    1706\n",
      "1.0    1266\n",
      "2.0    1007\n",
      "3.0     425\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405329994259156\n",
      "0.653496821071753\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_undersampled, average=\"macro\"))\n",
    "print(accuracy_score(y_pred, y_undersampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tensor_undersampled = torch.tensor(X_undersampled)\n",
    "embedding_dim = combined_tensor_test.shape[1]\n",
    "output_dim = 32\n",
    "model = EmbeddingAdjustmentModel(embedding_dim, output_dim)\n",
    "model.load_state_dict(torch.load('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/model_contrast_32.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "model = model.double() \n",
    "with torch.no_grad():\n",
    "    new_embeddings_test = model(combined_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_env_test = New_env(combined_tensor_test, torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7327"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7327/7327 [06:13<00:00, 19.62it/s]\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "y_pred = []\n",
    "s,_ =  career_env_test.reset(True)\n",
    "\n",
    "for t in tqdm(range(len(y_test))):\n",
    "    stay_a = 0\n",
    "    dbis=False\n",
    "    for k in range(6):\n",
    "        a = greedy_action(qfunctions[-1],s)\n",
    "        if a==0:\n",
    "            stay_a+=1\n",
    "            if stay_a ==2:\n",
    "                dbis=True\n",
    "        predicted_next_position, predicted_next_emb_state, reward, d, _ = career_env_test.step(a)\n",
    "        #print(\"s\", s)\n",
    "        s = predicted_next_emb_state\n",
    "\n",
    "        if d or dbis:\n",
    "            break\n",
    "    pred.append(s)\n",
    "    y_pred.append(predicted_next_position.item())\n",
    "    s,_=career_env_test.reset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "0.0    5770\n",
      "1.0     767\n",
      "2.0     716\n",
      "3.0      74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19295223120591057\n",
      "0.24457486010645557\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_test, average=\"macro\"))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2369557828085949\n",
      "0.255766343660434\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_test, average=\"macro\"))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20596223086716942\n",
      "0.24498430462672308\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_test, average=\"macro\"))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17024343425581262\n",
      "0.2537191210590965\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_test, average=\"macro\"))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_real = pd.read_csv(\"/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/y_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_map = {\n",
    "        0: \"Assistant\",\n",
    "        1:\"Executive\",\n",
    "        2:\"Manager\",\n",
    "        3 :\"Director\",\n",
    "    }\n",
    "y_pred_encoded = np.array([encoding_map[category] for category in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29273</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29274</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29275</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29276</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29277</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>36595</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>36596</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>36597</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>36598</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>36599</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   position\n",
       "0     29273  Executive\n",
       "1     29274  Executive\n",
       "2     29275  Executive\n",
       "3     29276   Director\n",
       "4     29277  Executive\n",
       "...     ...        ...\n",
       "7322  36595  Assistant\n",
       "7323  36596  Assistant\n",
       "7324  36597  Executive\n",
       "7325  36598  Assistant\n",
       "7326  36599    Manager\n",
       "\n",
       "[7327 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test_real.drop(['position'], axis=1, inplace=True)\n",
    "y_test_real[\"position\"] = y_pred_encoded\n",
    "\n",
    "y_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29273</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29274</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29275</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29276</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29277</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>36595</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>36596</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>36597</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>36598</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>36599</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   position\n",
       "0     29273    Manager\n",
       "1     29274  Assistant\n",
       "2     29275  Executive\n",
       "3     29276    Manager\n",
       "4     29277    Manager\n",
       "...     ...        ...\n",
       "7322  36595    Manager\n",
       "7323  36596  Assistant\n",
       "7324  36597  Executive\n",
       "7325  36598    Manager\n",
       "7326  36599  Executive\n",
       "\n",
       "[7327 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_real.to_csv('soumission_contrastive.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 25.722222222222214, 'Predicted label')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix @{:.2f}'.format(0.5))\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
