{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from env import MultiAgentEnv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "from new_env import New_env\n",
    "import gymnasium as gym\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('/Users/louisedurand-janin/Documents/GitHub/HrFlow_Data_Challenge/data/X_train.csv')\n",
    "X_train_df['employee embedding'] = X_train_df['employee embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float32))\n",
    "X_train_df['company embedding'] = X_train_df['company embedding'].apply(lambda x: np.array(json.loads(x), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    17793\n",
       "1    17793\n",
       "2    17793\n",
       "3    17793\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>employee embedding</th>\n",
       "      <th>company embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.013262551, -0.37616727, -0.61382735, 0.3597...</td>\n",
       "      <td>[0.39761704, 0.011816107, 0.1875633, 0.2807579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.28273815, -0.012908442, 0.20536786, 0.4824...</td>\n",
       "      <td>[0.3105131, -0.33802372, 0.023328865, 0.698560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.39998972, -0.29847285, -0.21097325, -0.0329...</td>\n",
       "      <td>[0.19704665, 0.062399972, 0.25658086, 0.255205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.39998972, -0.29847285, -0.21097325, -0.0329...</td>\n",
       "      <td>[0.6501612, -0.17757246, 0.14481378, 0.2488950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.01012421, 0.057610452, -0.1217429, 0.057732...</td>\n",
       "      <td>[0.5966811, -0.061620507, 0.056970306, 0.38894...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                 employee embedding  \\\n",
       "0           0   0  [0.013262551, -0.37616727, -0.61382735, 0.3597...   \n",
       "1           1   1  [-0.28273815, -0.012908442, 0.20536786, 0.4824...   \n",
       "2           2   2  [0.39998972, -0.29847285, -0.21097325, -0.0329...   \n",
       "3           3   3  [0.39998972, -0.29847285, -0.21097325, -0.0329...   \n",
       "4           4   4  [0.01012421, 0.057610452, -0.1217429, 0.057732...   \n",
       "\n",
       "                                   company embedding  \n",
       "0  [0.39761704, 0.011816107, 0.1875633, 0.2807579...  \n",
       "1  [0.3105131, -0.33802372, 0.023328865, 0.698560...  \n",
       "2  [0.19704665, 0.062399972, 0.25658086, 0.255205...  \n",
       "3  [0.6501612, -0.17757246, 0.14481378, 0.2488950...  \n",
       "4  [0.5966811, -0.061620507, 0.056970306, 0.38894...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('data/y_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes d'embeddings en tensors PyTorch\n",
    "employee_embedding_tensor = torch.tensor(np.vstack(X_resampled['employee embedding'].values), dtype=torch.float32)\n",
    "company_embedding_tensor = torch.tensor(np.vstack(X_resampled['company embedding'].values), dtype=torch.float32)\n",
    "\n",
    "# Concaténer les deux tensors le long de la dimension appropriée (axis=1 pour ajouter des colonnes)\n",
    "combined_tensor = torch.cat([employee_embedding_tensor, company_embedding_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(env, horizon, disable_tqdm=False, print_done_states=False):\n",
    "    s, _ = env.reset(True)\n",
    "    S = []\n",
    "    A = []\n",
    "    rewards = []\n",
    "    S2 = []\n",
    "    SA = []\n",
    "\n",
    "    D = []\n",
    "    #print(\"s\", s)\n",
    "    #print(\"true position\", env.y[env.index])\n",
    "\n",
    "    for _ in tqdm(range(horizon), disable=disable_tqdm):\n",
    "        a = env.sample_action()\n",
    "        s2, emb2s2, r, done, _ = env.step(a)\n",
    "        #print(\"next state preidcted\", s2)\n",
    "        #print(\"next embedding state \", emb2s2)\n",
    "        S.append(s)\n",
    "        #print('shape S', len(S))\n",
    "        A.append(a)\n",
    "        sa = torch.cat([s, torch.tensor(a)])\n",
    "        SA.append(sa)\n",
    "        rewards.append(r)\n",
    "        #print(\"reward\", r)\n",
    "        S2.append(emb2s2)\n",
    "        D.append(done)\n",
    "        if done:\n",
    "            s, _ = env.reset(False)\n",
    "            #print(\"new embedding\", s)\n",
    "            #print(\"true position\", env.y[env.index])\n",
    "            #print(\"done!\")\n",
    "        else:\n",
    "            s = emb2s2\n",
    "    S2 = np.array(S2)\n",
    "    S = np.array(S)\n",
    "    A = np.array(A)\n",
    "    D = np.array(D)\n",
    "    SA = np.array(SA)\n",
    "    rewards = np.array(rewards)\n",
    "    return S, A, rewards, S2, D, SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/p_k7b1g12kz9ykb1cx0n70w00000gn/T/ipykernel_15963/1229601373.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sa = torch.cat([s, torch.tensor(a)])\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3018.33it/s]\n"
     ]
    }
   ],
   "source": [
    "career_env = New_env(combined_tensor, y_train)\n",
    "S, A, R, S2, D, SA = collect_samples(career_env, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 66)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_fqi(S, A, R, S2, D, SA, iterations, nb_actions=2, gamma=0.9, disable_tqdm=False):\n",
    "    nb_samples = S.shape[0]\n",
    "    Qfunctions = []\n",
    "    #SA = np.append(S,A,axis=1)\n",
    "    for iter in tqdm(range(iterations), disable=disable_tqdm):\n",
    "        #print(\"iteration\", iter)\n",
    "        if iter==0:\n",
    "            value=R.copy()\n",
    "        else:\n",
    "            Q2 = np.zeros((nb_samples,nb_actions))\n",
    "            for a2 in range(nb_actions):\n",
    "                A2 = torch.full((S2.shape[0], 1), a2)\n",
    "                #print(A2.shape)\n",
    "                S2A2 = torch.cat([torch.from_numpy(S2), A2], dim=1)\n",
    "                S2A2_array = np.array(S2A2)\n",
    "                #print(\"shaoe A2S2\", S2A2_array.shape)\n",
    "                predictions = Qfunctions[-1].predict(S2A2_array)\n",
    "                #print(\"shape pred\", predictions.shape)\n",
    "                Q2[:,a2] = Qfunctions[-1].predict(S2A2_array)\n",
    "            max_Q2 = np.max(Q2,axis=1)\n",
    "            value = R + gamma*np.dot((1-D.flatten()),max_Q2)\n",
    "            #print(\"value\", value.shape)\n",
    "        Q = RandomForestRegressor()\n",
    "        Q.fit(SA,value)\n",
    "        Qfunctions.append(Q)\n",
    "    return Qfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "qfunctions = rf_fqi(S, A, R, S2, D, SA, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_action(Q,s,nb_actions=2):\n",
    "    Qsa = []\n",
    "    for a in range(nb_actions):\n",
    "        #print(\"s\", s)\n",
    "        print(\"a\", torch.tensor([a]))\n",
    "        sa = torch.cat([s, torch.tensor([a])], dim=0)\n",
    "        sa = np.array(sa)\n",
    "        #print(sa.reshape(-1,1).shape)\n",
    "        print(\"prediction\", Q.predict(sa.reshape(1, -1)))\n",
    "        Qsa.append(Q.predict(sa.reshape(1, -1)))\n",
    "    print(\"Qsa\", Qsa)\n",
    "    return np.argmax(Qsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0133, -0.3762, -0.6138,  ..., -0.4219, -0.3206, -0.4043],\n",
       "        [-0.2827, -0.0129,  0.2054,  ..., -0.1548,  0.0759, -0.6390],\n",
       "        [ 0.4000, -0.2985, -0.2110,  ..., -0.5598,  0.1031, -0.1492],\n",
       "        ...,\n",
       "        [-0.2505, -0.2068,  0.5609,  ..., -0.1784, -0.3287, -0.4991],\n",
       "        [-0.2505, -0.2068,  0.5609,  ..., -0.8119,  0.0043,  0.2834],\n",
       "        [-0.6191, -0.0630, -0.2045,  ..., -0.3501, -0.6396, -0.5535]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0133, -0.3762, -0.6138,  0.3597,  0.1939,  0.3880, -0.0020, -0.0196,\n",
      "         0.1618,  0.0734, -0.6540,  0.4437,  0.8655, -0.4937,  0.6503, -0.6351,\n",
      "        -0.5592, -0.7621,  0.9693, -0.4775, -0.4163,  0.8326,  0.4377,  0.0817,\n",
      "         0.6264,  0.4705, -0.2223,  0.6112, -0.8858, -0.1964, -0.4155, -0.8893,\n",
      "         0.3976,  0.0118,  0.1876,  0.2808, -0.3438, -0.2601, -0.2431, -0.0504,\n",
      "         0.1592, -0.1317, -0.5096, -0.2355,  0.8284, -0.6994,  0.4634,  0.3996,\n",
      "        -0.7340, -0.4339,  0.7385, -0.2088, -0.0800,  0.3684,  0.4964, -0.2953,\n",
      "         0.2941,  0.5663, -0.4504,  0.6678, -0.9076, -0.4219, -0.3206, -0.4043,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0133, -0.3762, -0.6138,  0.3597,  0.1939,  0.3880, -0.0020, -0.0196,\n",
      "         0.1618,  0.0734, -0.6540,  0.4437,  0.8655, -0.4937,  0.6503, -0.6351,\n",
      "        -0.5592, -0.7621,  0.9693, -0.4775, -0.4163,  0.8326,  0.4377,  0.0817,\n",
      "         0.6264,  0.4705, -0.2223,  0.6112, -0.8858, -0.1964, -0.4155, -0.8893,\n",
      "         0.3976,  0.0118,  0.1876,  0.2808, -0.3438, -0.2601, -0.2431, -0.0504,\n",
      "         0.1592, -0.1317, -0.5096, -0.2355,  0.8284, -0.6994,  0.4634,  0.3996,\n",
      "        -0.7340, -0.4339,  0.7385, -0.2088, -0.0800,  0.3684,  0.4964, -0.2953,\n",
      "         0.2941,  0.5663, -0.4504,  0.6678, -0.9076, -0.4219, -0.3206, -0.4043,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0133, -0.3762, -0.6138,  0.3597,  0.1939,  0.3880, -0.0020, -0.0196,\n",
      "         0.1618,  0.0734, -0.6540,  0.4437,  0.8655, -0.4937,  0.6503, -0.6351,\n",
      "        -0.5592, -0.7621,  0.9693, -0.4775, -0.4163,  0.8326,  0.4377,  0.0817,\n",
      "         0.6264,  0.4705, -0.2223,  0.6112, -0.8858, -0.1964, -0.4155, -0.8893,\n",
      "         0.3976,  0.0118,  0.1876,  0.2808, -0.3438, -0.2601, -0.2431, -0.0504,\n",
      "         0.1592, -0.1317, -0.5096, -0.2355,  0.8284, -0.6994,  0.4634,  0.3996,\n",
      "        -0.7340, -0.4339,  0.7385, -0.2088, -0.0800,  0.3684,  0.4964, -0.2953,\n",
      "         0.2941,  0.5663, -0.4504,  0.6678, -0.9076, -0.4219, -0.3206, -0.4043,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0133, -0.3762, -0.6138,  0.3597,  0.1939,  0.3880, -0.0020, -0.0196,\n",
      "         0.1618,  0.0734, -0.6540,  0.4437,  0.8655, -0.4937,  0.6503, -0.6351,\n",
      "        -0.5592, -0.7621,  0.9693, -0.4775, -0.4163,  0.8326,  0.4377,  0.0817,\n",
      "         0.6264,  0.4705, -0.2223,  0.6112, -0.8858, -0.1964, -0.4155, -0.8893,\n",
      "         0.3976,  0.0118,  0.1876,  0.2808, -0.3438, -0.2601, -0.2431, -0.0504,\n",
      "         0.1592, -0.1317, -0.5096, -0.2355,  0.8284, -0.6994,  0.4634,  0.3996,\n",
      "        -0.7340, -0.4339,  0.7385, -0.2088, -0.0800,  0.3684,  0.4964, -0.2953,\n",
      "         0.2941,  0.5663, -0.4504,  0.6678, -0.9076, -0.4219, -0.3206, -0.4043,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0133, -0.3762, -0.6138,  0.3597,  0.1939,  0.3880, -0.0020, -0.0196,\n",
      "         0.1618,  0.0734, -0.6540,  0.4437,  0.8655, -0.4937,  0.6503, -0.6351,\n",
      "        -0.5592, -0.7621,  0.9693, -0.4775, -0.4163,  0.8326,  0.4377,  0.0817,\n",
      "         0.6264,  0.4705, -0.2223,  0.6112, -0.8858, -0.1964, -0.4155, -0.8893,\n",
      "         0.3976,  0.0118,  0.1876,  0.2808, -0.3438, -0.2601, -0.2431, -0.0504,\n",
      "         0.1592, -0.1317, -0.5096, -0.2355,  0.8284, -0.6994,  0.4634,  0.3996,\n",
      "        -0.7340, -0.4339,  0.7385, -0.2088, -0.0800,  0.3684,  0.4964, -0.2953,\n",
      "         0.2941,  0.5663, -0.4504,  0.6678, -0.9076, -0.4219, -0.3206, -0.4043,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([-0.2827, -0.0129,  0.2054,  0.4825,  0.2856, -0.2614,  0.6029, -0.1760,\n",
      "         0.3519, -0.4839, -0.2518, -0.0331,  0.8443, -0.4500,  0.3562,  0.0797,\n",
      "        -0.8423, -0.5320,  0.8383,  0.0091, -0.2785, -0.0536,  0.6434,  0.1177,\n",
      "        -0.8556,  0.4864, -0.5582,  0.3834, -0.8555, -0.4751, -0.2321, -0.6162,\n",
      "         0.3105, -0.3380,  0.0233,  0.6986,  0.5519,  0.7733,  0.1414, -0.0823,\n",
      "         0.0517,  0.0631, -0.6123,  0.3498,  0.9053, -0.8817,  0.4932,  0.4980,\n",
      "        -0.8102, -0.9034,  0.8123,  0.7521, -0.0451, -0.5596,  0.5345, -0.2099,\n",
      "         0.6646,  0.5392, -0.3674,  0.6396, -0.8696, -0.1548,  0.0759, -0.6390,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([-0.2827, -0.0129,  0.2054,  0.4825,  0.2856, -0.2614,  0.6029, -0.1760,\n",
      "         0.3519, -0.4839, -0.2518, -0.0331,  0.8443, -0.4500,  0.3562,  0.0797,\n",
      "        -0.8423, -0.5320,  0.8383,  0.0091, -0.2785, -0.0536,  0.6434,  0.1177,\n",
      "        -0.8556,  0.4864, -0.5582,  0.3834, -0.8555, -0.4751, -0.2321, -0.6162,\n",
      "         0.3105, -0.3380,  0.0233,  0.6986,  0.5519,  0.7733,  0.1414, -0.0823,\n",
      "         0.0517,  0.0631, -0.6123,  0.3498,  0.9053, -0.8817,  0.4932,  0.4980,\n",
      "        -0.8102, -0.9034,  0.8123,  0.7521, -0.0451, -0.5596,  0.5345, -0.2099,\n",
      "         0.6646,  0.5392, -0.3674,  0.6396, -0.8696, -0.1548,  0.0759, -0.6390,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([-0.2827, -0.0129,  0.2054,  0.4825,  0.2856, -0.2614,  0.6029, -0.1760,\n",
      "         0.3519, -0.4839, -0.2518, -0.0331,  0.8443, -0.4500,  0.3562,  0.0797,\n",
      "        -0.8423, -0.5320,  0.8383,  0.0091, -0.2785, -0.0536,  0.6434,  0.1177,\n",
      "        -0.8556,  0.4864, -0.5582,  0.3834, -0.8555, -0.4751, -0.2321, -0.6162,\n",
      "         0.3105, -0.3380,  0.0233,  0.6986,  0.5519,  0.7733,  0.1414, -0.0823,\n",
      "         0.0517,  0.0631, -0.6123,  0.3498,  0.9053, -0.8817,  0.4932,  0.4980,\n",
      "        -0.8102, -0.9034,  0.8123,  0.7521, -0.0451, -0.5596,  0.5345, -0.2099,\n",
      "         0.6646,  0.5392, -0.3674,  0.6396, -0.8696, -0.1548,  0.0759, -0.6390,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([-0.2827, -0.0129,  0.2054,  0.4825,  0.2856, -0.2614,  0.6029, -0.1760,\n",
      "         0.3519, -0.4839, -0.2518, -0.0331,  0.8443, -0.4500,  0.3562,  0.0797,\n",
      "        -0.8423, -0.5320,  0.8383,  0.0091, -0.2785, -0.0536,  0.6434,  0.1177,\n",
      "        -0.8556,  0.4864, -0.5582,  0.3834, -0.8555, -0.4751, -0.2321, -0.6162,\n",
      "         0.3105, -0.3380,  0.0233,  0.6986,  0.5519,  0.7733,  0.1414, -0.0823,\n",
      "         0.0517,  0.0631, -0.6123,  0.3498,  0.9053, -0.8817,  0.4932,  0.4980,\n",
      "        -0.8102, -0.9034,  0.8123,  0.7521, -0.0451, -0.5596,  0.5345, -0.2099,\n",
      "         0.6646,  0.5392, -0.3674,  0.6396, -0.8696, -0.1548,  0.0759, -0.6390,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([-0.2827, -0.0129,  0.2054,  0.4825,  0.2856, -0.2614,  0.6029, -0.1760,\n",
      "         0.3519, -0.4839, -0.2518, -0.0331,  0.8443, -0.4500,  0.3562,  0.0797,\n",
      "        -0.8423, -0.5320,  0.8383,  0.0091, -0.2785, -0.0536,  0.6434,  0.1177,\n",
      "        -0.8556,  0.4864, -0.5582,  0.3834, -0.8555, -0.4751, -0.2321, -0.6162,\n",
      "         0.3105, -0.3380,  0.0233,  0.6986,  0.5519,  0.7733,  0.1414, -0.0823,\n",
      "         0.0517,  0.0631, -0.6123,  0.3498,  0.9053, -0.8817,  0.4932,  0.4980,\n",
      "        -0.8102, -0.9034,  0.8123,  0.7521, -0.0451, -0.5596,  0.5345, -0.2099,\n",
      "         0.6646,  0.5392, -0.3674,  0.6396, -0.8696, -0.1548,  0.0759, -0.6390,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.1970,  0.0624,  0.2566,  0.2552, -0.3004,  0.1313,  0.7291, -0.0433,\n",
      "         0.2197, -0.2048, -0.1531,  0.2865,  0.6419, -0.6259,  0.7422,  0.1051,\n",
      "        -0.8439, -0.4147,  0.6958,  0.0101, -0.0772, -0.0851,  0.1257,  0.1401,\n",
      "         0.0807,  0.2333, -0.2380,  0.5642, -0.9308, -0.5598,  0.1031, -0.1492,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.1970,  0.0624,  0.2566,  0.2552, -0.3004,  0.1313,  0.7291, -0.0433,\n",
      "         0.2197, -0.2048, -0.1531,  0.2865,  0.6419, -0.6259,  0.7422,  0.1051,\n",
      "        -0.8439, -0.4147,  0.6958,  0.0101, -0.0772, -0.0851,  0.1257,  0.1401,\n",
      "         0.0807,  0.2333, -0.2380,  0.5642, -0.9308, -0.5598,  0.1031, -0.1492,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.1970,  0.0624,  0.2566,  0.2552, -0.3004,  0.1313,  0.7291, -0.0433,\n",
      "         0.2197, -0.2048, -0.1531,  0.2865,  0.6419, -0.6259,  0.7422,  0.1051,\n",
      "        -0.8439, -0.4147,  0.6958,  0.0101, -0.0772, -0.0851,  0.1257,  0.1401,\n",
      "         0.0807,  0.2333, -0.2380,  0.5642, -0.9308, -0.5598,  0.1031, -0.1492,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.1970,  0.0624,  0.2566,  0.2552, -0.3004,  0.1313,  0.7291, -0.0433,\n",
      "         0.2197, -0.2048, -0.1531,  0.2865,  0.6419, -0.6259,  0.7422,  0.1051,\n",
      "        -0.8439, -0.4147,  0.6958,  0.0101, -0.0772, -0.0851,  0.1257,  0.1401,\n",
      "         0.0807,  0.2333, -0.2380,  0.5642, -0.9308, -0.5598,  0.1031, -0.1492,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.1970,  0.0624,  0.2566,  0.2552, -0.3004,  0.1313,  0.7291, -0.0433,\n",
      "         0.2197, -0.2048, -0.1531,  0.2865,  0.6419, -0.6259,  0.7422,  0.1051,\n",
      "        -0.8439, -0.4147,  0.6958,  0.0101, -0.0772, -0.0851,  0.1257,  0.1401,\n",
      "         0.0807,  0.2333, -0.2380,  0.5642, -0.9308, -0.5598,  0.1031, -0.1492,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.6502, -0.1776,  0.1448,  0.2489,  0.1052, -0.3583, -0.1194, -0.1658,\n",
      "         0.0213, -0.1558, -0.4814,  0.4913,  0.8825, -0.5810,  0.3973,  0.6109,\n",
      "        -0.5810, -0.2572,  0.8946,  0.2657, -0.1693,  0.1468,  0.4136, -0.1097,\n",
      "         0.3227,  0.5083, -0.3691,  0.4966, -0.8811, -0.0561,  0.5569, -0.2026,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.6502, -0.1776,  0.1448,  0.2489,  0.1052, -0.3583, -0.1194, -0.1658,\n",
      "         0.0213, -0.1558, -0.4814,  0.4913,  0.8825, -0.5810,  0.3973,  0.6109,\n",
      "        -0.5810, -0.2572,  0.8946,  0.2657, -0.1693,  0.1468,  0.4136, -0.1097,\n",
      "         0.3227,  0.5083, -0.3691,  0.4966, -0.8811, -0.0561,  0.5569, -0.2026,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.6502, -0.1776,  0.1448,  0.2489,  0.1052, -0.3583, -0.1194, -0.1658,\n",
      "         0.0213, -0.1558, -0.4814,  0.4913,  0.8825, -0.5810,  0.3973,  0.6109,\n",
      "        -0.5810, -0.2572,  0.8946,  0.2657, -0.1693,  0.1468,  0.4136, -0.1097,\n",
      "         0.3227,  0.5083, -0.3691,  0.4966, -0.8811, -0.0561,  0.5569, -0.2026,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.6502, -0.1776,  0.1448,  0.2489,  0.1052, -0.3583, -0.1194, -0.1658,\n",
      "         0.0213, -0.1558, -0.4814,  0.4913,  0.8825, -0.5810,  0.3973,  0.6109,\n",
      "        -0.5810, -0.2572,  0.8946,  0.2657, -0.1693,  0.1468,  0.4136, -0.1097,\n",
      "         0.3227,  0.5083, -0.3691,  0.4966, -0.8811, -0.0561,  0.5569, -0.2026,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.4000, -0.2985, -0.2110, -0.0330,  0.0577,  0.4211,  0.9499, -0.3652,\n",
      "         0.3271,  0.0154, -0.6524,  0.2462,  0.6395,  0.1134,  0.1327,  0.1740,\n",
      "        -0.4223, -0.2147,  0.6501,  0.1185, -0.1098,  0.3551, -0.2606,  0.1414,\n",
      "         0.8342,  0.3537,  0.2037,  0.6772, -0.8374, -0.7139,  0.3767,  0.3582,\n",
      "         0.6502, -0.1776,  0.1448,  0.2489,  0.1052, -0.3583, -0.1194, -0.1658,\n",
      "         0.0213, -0.1558, -0.4814,  0.4913,  0.8825, -0.5810,  0.3973,  0.6109,\n",
      "        -0.5810, -0.2572,  0.8946,  0.2657, -0.1693,  0.1468,  0.4136, -0.1097,\n",
      "         0.3227,  0.5083, -0.3691,  0.4966, -0.8811, -0.0561,  0.5569, -0.2026,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0101,  0.0576, -0.1217,  0.0577,  0.0841, -0.0444,  0.1557, -0.1251,\n",
      "         0.2374, -0.1255, -0.4926, -0.0495,  0.6713, -0.3057,  0.2721,  0.0468,\n",
      "        -0.6739, -0.3194,  0.6183, -0.2338, -0.2771,  0.1647,  0.3939, -0.0340,\n",
      "         0.3103,  0.3486, -0.4926,  0.3858, -0.7622, -0.4909,  0.3286, -0.6500,\n",
      "         0.5967, -0.0616,  0.0570,  0.3889, -0.1005, -0.0692,  0.4468,  0.1732,\n",
      "         0.2056, -0.1761, -0.5810, -0.3974,  0.8413, -0.5063,  0.5519,  0.0762,\n",
      "        -0.8461, -0.5938,  0.6159,  0.1864, -0.1213,  0.4619,  0.4168,  0.4083,\n",
      "         0.3371,  0.3925, -0.2656,  0.6650, -0.9220, -0.5055, -0.3642, -0.0737,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0101,  0.0576, -0.1217,  0.0577,  0.0841, -0.0444,  0.1557, -0.1251,\n",
      "         0.2374, -0.1255, -0.4926, -0.0495,  0.6713, -0.3057,  0.2721,  0.0468,\n",
      "        -0.6739, -0.3194,  0.6183, -0.2338, -0.2771,  0.1647,  0.3939, -0.0340,\n",
      "         0.3103,  0.3486, -0.4926,  0.3858, -0.7622, -0.4909,  0.3286, -0.6500,\n",
      "         0.5967, -0.0616,  0.0570,  0.3889, -0.1005, -0.0692,  0.4468,  0.1732,\n",
      "         0.2056, -0.1761, -0.5810, -0.3974,  0.8413, -0.5063,  0.5519,  0.0762,\n",
      "        -0.8461, -0.5938,  0.6159,  0.1864, -0.1213,  0.4619,  0.4168,  0.4083,\n",
      "         0.3371,  0.3925, -0.2656,  0.6650, -0.9220, -0.5055, -0.3642, -0.0737,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0101,  0.0576, -0.1217,  0.0577,  0.0841, -0.0444,  0.1557, -0.1251,\n",
      "         0.2374, -0.1255, -0.4926, -0.0495,  0.6713, -0.3057,  0.2721,  0.0468,\n",
      "        -0.6739, -0.3194,  0.6183, -0.2338, -0.2771,  0.1647,  0.3939, -0.0340,\n",
      "         0.3103,  0.3486, -0.4926,  0.3858, -0.7622, -0.4909,  0.3286, -0.6500,\n",
      "         0.5967, -0.0616,  0.0570,  0.3889, -0.1005, -0.0692,  0.4468,  0.1732,\n",
      "         0.2056, -0.1761, -0.5810, -0.3974,  0.8413, -0.5063,  0.5519,  0.0762,\n",
      "        -0.8461, -0.5938,  0.6159,  0.1864, -0.1213,  0.4619,  0.4168,  0.4083,\n",
      "         0.3371,  0.3925, -0.2656,  0.6650, -0.9220, -0.5055, -0.3642, -0.0737,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0101,  0.0576, -0.1217,  0.0577,  0.0841, -0.0444,  0.1557, -0.1251,\n",
      "         0.2374, -0.1255, -0.4926, -0.0495,  0.6713, -0.3057,  0.2721,  0.0468,\n",
      "        -0.6739, -0.3194,  0.6183, -0.2338, -0.2771,  0.1647,  0.3939, -0.0340,\n",
      "         0.3103,  0.3486, -0.4926,  0.3858, -0.7622, -0.4909,  0.3286, -0.6500,\n",
      "         0.5967, -0.0616,  0.0570,  0.3889, -0.1005, -0.0692,  0.4468,  0.1732,\n",
      "         0.2056, -0.1761, -0.5810, -0.3974,  0.8413, -0.5063,  0.5519,  0.0762,\n",
      "        -0.8461, -0.5938,  0.6159,  0.1864, -0.1213,  0.4619,  0.4168,  0.4083,\n",
      "         0.3371,  0.3925, -0.2656,  0.6650, -0.9220, -0.5055, -0.3642, -0.0737,\n",
      "         0.0000])\n",
      "a tensor([0])\n",
      "prediction [-3.73505772e+11]\n",
      "a tensor([1])\n",
      "prediction [-3.73505772e+11]\n",
      "Qsa [array([-3.73505772e+11]), array([-3.73505772e+11])]\n",
      "s tensor([ 0.0101,  0.0576, -0.1217,  0.0577,  0.0841, -0.0444,  0.1557, -0.1251,\n",
      "         0.2374, -0.1255, -0.4926, -0.0495,  0.6713, -0.3057,  0.2721,  0.0468,\n",
      "        -0.6739, -0.3194,  0.6183, -0.2338, -0.2771,  0.1647,  0.3939, -0.0340,\n",
      "         0.3103,  0.3486, -0.4926,  0.3858, -0.7622, -0.4909,  0.3286, -0.6500,\n",
      "         0.5967, -0.0616,  0.0570,  0.3889, -0.1005, -0.0692,  0.4468,  0.1732,\n",
      "         0.2056, -0.1761, -0.5810, -0.3974,  0.8413, -0.5063,  0.5519,  0.0762,\n",
      "        -0.8461, -0.5938,  0.6159,  0.1864, -0.1213,  0.4619,  0.4168,  0.4083,\n",
      "         0.3371,  0.3925, -0.2656,  0.6650, -0.9220, -0.5055, -0.3642, -0.0737,\n",
      "         0.0000])\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "y_pred = []\n",
    "s,_ =  career_env.reset(True)\n",
    "\n",
    "for t in range(5):\n",
    "    for k in range(5):\n",
    "        a = greedy_action(qfunctions[-1],s)\n",
    "        predicted_next_position, predicted_next_emb_state, reward, d, _ = career_env.step(a)\n",
    "        print(\"s\", s)\n",
    "        s = predicted_next_emb_state\n",
    "\n",
    "        if d:\n",
    "            break\n",
    "    pred.append(s)\n",
    "    y_pred.append(predicted_next_position.item())\n",
    "    s,_=career_env.reset(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DQNAgent(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQNAgent, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0   # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        self.fc1 = nn.Linear(state_size, 24)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.fc3 = nn.Linear(24, action_size)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.relu(self.fc1(state))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        act_values = self.forward(state)\n",
    "        return np.argmax(act_values.cpu().data.numpy())\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            state = torch.FloatTensor(state).unsqueeze(0)\n",
    "            next_state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.forward(next_state).cpu().data.numpy())\n",
    "            target_f = self.forward(state)\n",
    "            target_f[0][action] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = nn.MSELoss()(target_f, target_f)  # Note: You might want to adjust this loss calculation.\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action(network, state):\n",
    "    device = \"cuda\" if next(network.parameters()).is_cuda else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        Q = network(torch.Tensor(state).unsqueeze(0).to(device))\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from solutions.replay_buffer2 import ReplayBuffer\n",
    "#from solutions.dqn_greedy_action import greedy_action\n",
    "\n",
    "class dqn_agent:\n",
    "    def __init__(self, config, model):\n",
    "        device = \"cuda\" if next(model.parameters()).is_cuda else \"cpu\"\n",
    "        self.gamma = config['gamma']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.nb_actions = config['nb_actions']\n",
    "        #self.memory = ReplayBuffer(config['buffer_size'], device)\n",
    "        self.epsilon_max = config['epsilon_max']\n",
    "        self.epsilon_min = config['epsilon_min']\n",
    "        self.epsilon_stop = config['epsilon_decay_period']\n",
    "        self.epsilon_delay = config['epsilon_delay_decay']\n",
    "        self.epsilon_step = (self.epsilon_max-self.epsilon_min)/self.epsilon_stop\n",
    "        self.model = model \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    def gradient_step(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
    "            QYmax = self.model(Y).max(1)[0].detach()\n",
    "            #update = torch.addcmul(R, self.gamma, 1-D, QYmax)\n",
    "            update = torch.addcmul(R, 1-D, QYmax, value=self.gamma)\n",
    "            QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
    "            loss = self.criterion(QXA, update.unsqueeze(1))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "    def train(self, env, max_episode):\n",
    "        episode_return = []\n",
    "        episode = 0\n",
    "        episode_cum_reward = 0\n",
    "        state, _ = env.reset()\n",
    "        epsilon = self.epsilon_max\n",
    "        step = 0\n",
    "\n",
    "        while episode < max_episode:\n",
    "            # update epsilon\n",
    "            if step > self.epsilon_delay:\n",
    "                epsilon = max(self.epsilon_min, epsilon-self.epsilon_step)\n",
    "\n",
    "            # select epsilon-greedy action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = greedy_action(self.model, state)\n",
    "\n",
    "            # step\n",
    "            next_state, reward, done, trunc, _ = env.step(action)\n",
    "            self.memory.append(state, action, reward, next_state, done)\n",
    "            episode_cum_reward += reward\n",
    "\n",
    "            # train\n",
    "            self.gradient_step()\n",
    "\n",
    "            # next transition\n",
    "            step += 1\n",
    "\n",
    "            if done:\n",
    "                episode += 1\n",
    "                print(\"Episode \", '{:3d}'.format(episode), \n",
    "                      \", epsilon \", '{:6.2f}'.format(epsilon), \n",
    "                      \", batch size \", '{:5d}'.format(len(self.memory)), \n",
    "                      \", episode return \", '{:4.1f}'.format(episode_cum_reward),\n",
    "                      sep='')\n",
    "                state, _ = env.reset()\n",
    "                episode_return.append(episode_cum_reward)\n",
    "                episode_cum_reward = 0\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "        return episode_return\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
